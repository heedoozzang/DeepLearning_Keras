{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngbinYoon/DeepLearning_Keras/blob/master/PantsModel_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJHOJx7-3cey",
        "colab_type": "code",
        "outputId": "f4623769-e2c0-4065-914e-5dc3e3001442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XuSY7jB4f1N",
        "colab_type": "code",
        "outputId": "794b0013-0447-458e-fdb8-5c01914799f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI9SaqJr3lCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEBgP_6L5qFf",
        "colab_type": "code",
        "outputId": "d5fe8a7f-3434-4584-ba19-3c8903419078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jMX1Xiv3sJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 소규모 데이터셋을 저장할 디렉터리\n",
        "base_dir = '/content/drive/My Drive/KerasTask/data/pants'\n",
        "\n",
        "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbo12XLl4wqt",
        "colab_type": "code",
        "outputId": "b1253d41-a878-4e72-ee17-7e7203bd1961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# 학습용 디렉터리\n",
        "train_jean_dark_plain = os.path.join(train_dir, 'bottom_jean_dark_plain')\n",
        "train_jean_light_plain = os.path.join(train_dir, 'bottom_jean_light_plain')\n",
        "train_pants_black_plain = os.path.join(train_dir, 'bottom_pants_black_plain')\n",
        "train_pants_brown_plain = os.path.join(train_dir, 'bottom_pants_brown_plain')\n",
        "train_pants_green_plain = os.path.join(train_dir, 'bottom_pants_green_plain')\n",
        "train_pants_grey_plain = os.path.join(train_dir, 'bottom_pants_grey_plain')\n",
        "train_pants_white_plain = os.path.join(train_dir, 'bottom_pants_white_plain')\n",
        "\n",
        "print('훈련 bottom_jean_dark_plain:', len(os.listdir(train_jean_dark_plain)))\n",
        "print('훈련 bottom_jean_light_plain:', len(os.listdir(train_jean_light_plain)))\n",
        "print('훈련 bottom_pants_black_plain:', len(os.listdir(train_pants_black_plain)))\n",
        "print('훈련 bottom_pants_brown_plain:', len(os.listdir(train_pants_brown_plain)))\n",
        "print('훈련 bottom_pants_green_plain:', len(os.listdir(train_pants_green_plain)))\n",
        "print('훈련 bottom_pants_grey_plain:', len(os.listdir(train_pants_grey_plain)))\n",
        "print('훈련 bottom_pants_white_plain:', len(os.listdir(train_pants_white_plain)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 bottom_jean_dark_plain: 132\n",
            "훈련 bottom_jean_light_plain: 55\n",
            "훈련 bottom_pants_black_plain: 94\n",
            "훈련 bottom_pants_brown_plain: 44\n",
            "훈련 bottom_pants_green_plain: 43\n",
            "훈련 bottom_pants_grey_plain: 47\n",
            "훈련 bottom_pants_white_plain: 52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALKs0kjf6J4K",
        "colab_type": "code",
        "outputId": "e7c28115-21b9-4007-a4f4-3bce550352a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# 검증용 고양이 사진 디렉터리\n",
        "validation_jean_dark_plain = os.path.join(validation_dir, 'bottom_jean_dark_plain')\n",
        "validation_jean_light_plain = os.path.join(validation_dir, 'bottom_jean_light_plain')\n",
        "validation_pants_black_plain = os.path.join(validation_dir, 'bottom_pants_black_plain')\n",
        "validation_pants_brown_plain = os.path.join(validation_dir, 'bottom_pants_brown_plain')\n",
        "validation_pants_green_plain = os.path.join(validation_dir, 'bottom_pants_green_plain')\n",
        "validation_pants_grey_plain = os.path.join(validation_dir, 'bottom_pants_grey_plain')\n",
        "validation_pants_white_plain = os.path.join(validation_dir, 'bottom_pants_white_plain')\n",
        "\n",
        "\n",
        "# 테스트용 고양이 사진 디렉터리\n",
        "test_jean_dark_plain = os.path.join(test_dir, 'bottom_jean_dark_plain')\n",
        "test_jean_light_plain = os.path.join(test_dir, 'bottom_jean_light_plain')\n",
        "test_pants_black_plain = os.path.join(test_dir, 'bottom_pants_black_plain')\n",
        "test_pants_brown_plain = os.path.join(test_dir, 'bottom_pants_brown_plain')\n",
        "test_pants_green_plain = os.path.join(test_dir, 'bottom_pants_green_plain')\n",
        "test_pants_grey_plain = os.path.join(test_dir, 'bottom_pants_grey_plain')\n",
        "test_pants_white_plain = os.path.join(test_dir, 'bottom_pants_white_plain')\n",
        "\n",
        "print('검증 bottom_jean_dark_plain:', len(os.listdir(validation_jean_dark_plain)))\n",
        "print('검증 bottom_jean_light_plain:', len(os.listdir(validation_jean_light_plain)))\n",
        "print('검증 bottom_pants_black_plain:', len(os.listdir(validation_pants_black_plain)))\n",
        "print('검증 bottom_pants_brown_plain:', len(os.listdir(validation_pants_brown_plain)))\n",
        "print('검증 bottom_pants_green_plain:', len(os.listdir(validation_pants_green_plain)))\n",
        "print('검증 bottom_pants_grey_plain:', len(os.listdir(validation_pants_grey_plain)))\n",
        "print('검증 bottom_pants_white_plain:', len(os.listdir(validation_pants_white_plain)))\n",
        "\n",
        "print('테스트 bottom_jean_dark_plain:', len(os.listdir(test_jean_dark_plain)))\n",
        "print('테스트 bottom_jean_light_plain:', len(os.listdir(test_jean_light_plain)))\n",
        "print('테스트 bottom_pants_black_plain:', len(os.listdir(test_pants_black_plain)))\n",
        "print('테스트 bottom_pants_brown_plain:', len(os.listdir(test_pants_brown_plain)))\n",
        "print('테스트 bottom_pants_green_plain:', len(os.listdir(test_pants_green_plain)))\n",
        "print('테스트 bottom_pants_grey_plain:', len(os.listdir(test_pants_grey_plain)))\n",
        "print('테스트 bottom_pants_white_plain:', len(os.listdir(test_pants_white_plain)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "검증 bottom_jean_dark_plain: 20\n",
            "검증 bottom_jean_light_plain: 20\n",
            "검증 bottom_pants_black_plain: 20\n",
            "검증 bottom_pants_brown_plain: 20\n",
            "검증 bottom_pants_green_plain: 20\n",
            "검증 bottom_pants_grey_plain: 20\n",
            "검증 bottom_pants_white_plain: 20\n",
            "테스트 bottom_jean_dark_plain: 11\n",
            "테스트 bottom_jean_light_plain: 11\n",
            "테스트 bottom_pants_black_plain: 11\n",
            "테스트 bottom_pants_brown_plain: 11\n",
            "테스트 bottom_pants_green_plain: 11\n",
            "테스트 bottom_pants_grey_plain: 11\n",
            "테스트 bottom_pants_white_plain: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XShtWiRHE3X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.layers import Dense, Input, Activation\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mro6kZi6JCk",
        "colab_type": "code",
        "outputId": "4b46d2d3-7cba-4c8f-f44a-85097cee2649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "conv_base = ResNet50(weights = 'imagenet',\n",
        "                    include_top = False,\n",
        "                    input_shape = (150,150,3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJXiIYlaE_Na",
        "colab_type": "code",
        "outputId": "94e78133-270e-4e20-b8ec-b30ae167e1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4JlxmDmFHx-",
        "colab_type": "code",
        "outputId": "1dfb5af2-8582-4339-a568-ed43031963fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(7, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBQ0Au5KFJ-d",
        "colab_type": "code",
        "outputId": "9651033f-5aad-4c1b-aa21-43e0b81e0154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 1799      \n",
            "=================================================================\n",
            "Total params: 36,696,967\n",
            "Trainable params: 36,643,847\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAk15uZ_FOKN",
        "colab_type": "code",
        "outputId": "c0008c19-5a04-4b32-ba4c-6a02cfbec9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('conv_base를 동결하기 전 훈련되는 가중치의 수:', \n",
        "      len(model.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print('conv_base를 동결한 후 훈련되는 가중치의 수:', \n",
        "      len(model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv_base를 동결하기 전 훈련되는 가중치의 수: 216\n",
            "conv_base를 동결한 후 훈련되는 가중치의 수: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGLLEWe2FRL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.layers import Dense, Input, Activation\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8xggCV9FiXK",
        "colab_type": "code",
        "outputId": "b3bfcb5b-3096-4027-f8b8-ffabe370f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=200,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 467 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            " - 297s - loss: 0.4284 - acc: 0.8556 - val_loss: 2.1977 - val_acc: 0.0571\n",
            "Epoch 2/100\n",
            " - 84s - loss: 0.1450 - acc: 0.9510 - val_loss: 2.2334 - val_acc: 0.1000\n",
            "Epoch 3/100\n",
            " - 86s - loss: 0.1210 - acc: 0.9573 - val_loss: 2.2758 - val_acc: 0.1500\n",
            "Epoch 4/100\n",
            " - 83s - loss: 0.0888 - acc: 0.9714 - val_loss: 2.3665 - val_acc: 0.0929\n",
            "Epoch 5/100\n",
            " - 84s - loss: 0.0829 - acc: 0.9708 - val_loss: 2.5018 - val_acc: 0.0357\n",
            "Epoch 6/100\n",
            " - 86s - loss: 0.0691 - acc: 0.9764 - val_loss: 2.5330 - val_acc: 0.0357\n",
            "Epoch 7/100\n",
            " - 83s - loss: 0.0576 - acc: 0.9802 - val_loss: 2.6433 - val_acc: 0.1143\n",
            "Epoch 8/100\n",
            " - 83s - loss: 0.0462 - acc: 0.9839 - val_loss: 2.8638 - val_acc: 0.1429\n",
            "Epoch 9/100\n",
            " - 87s - loss: 0.0601 - acc: 0.9822 - val_loss: 2.7941 - val_acc: 0.1429\n",
            "Epoch 10/100\n",
            " - 83s - loss: 0.0541 - acc: 0.9827 - val_loss: 2.9148 - val_acc: 0.1429\n",
            "Epoch 11/100\n",
            " - 83s - loss: 0.0427 - acc: 0.9862 - val_loss: 3.0830 - val_acc: 0.1429\n",
            "Epoch 12/100\n",
            " - 86s - loss: 0.0540 - acc: 0.9837 - val_loss: 3.0506 - val_acc: 0.1429\n",
            "Epoch 13/100\n",
            " - 84s - loss: 0.0374 - acc: 0.9886 - val_loss: 3.1253 - val_acc: 0.1429\n",
            "Epoch 14/100\n",
            " - 83s - loss: 0.0362 - acc: 0.9875 - val_loss: 3.3518 - val_acc: 0.1429\n",
            "Epoch 15/100\n",
            " - 85s - loss: 0.0402 - acc: 0.9863 - val_loss: 3.5203 - val_acc: 0.1429\n",
            "Epoch 16/100\n",
            " - 84s - loss: 0.0389 - acc: 0.9878 - val_loss: 3.5028 - val_acc: 0.1429\n",
            "Epoch 17/100\n",
            " - 83s - loss: 0.0311 - acc: 0.9900 - val_loss: 3.6711 - val_acc: 0.1429\n",
            "Epoch 18/100\n",
            " - 86s - loss: 0.0350 - acc: 0.9892 - val_loss: 3.4990 - val_acc: 0.1429\n",
            "Epoch 19/100\n",
            " - 83s - loss: 0.0275 - acc: 0.9902 - val_loss: 3.5841 - val_acc: 0.1429\n",
            "Epoch 20/100\n",
            " - 83s - loss: 0.0277 - acc: 0.9912 - val_loss: 3.8734 - val_acc: 0.1429\n",
            "Epoch 21/100\n",
            " - 86s - loss: 0.0252 - acc: 0.9926 - val_loss: 3.8781 - val_acc: 0.1429\n",
            "Epoch 22/100\n",
            " - 83s - loss: 0.0388 - acc: 0.9887 - val_loss: 3.9680 - val_acc: 0.1429\n",
            "Epoch 23/100\n",
            " - 83s - loss: 0.0271 - acc: 0.9911 - val_loss: 4.0015 - val_acc: 0.1429\n",
            "Epoch 24/100\n",
            " - 86s - loss: 0.0294 - acc: 0.9893 - val_loss: 4.2587 - val_acc: 0.1429\n",
            "Epoch 25/100\n",
            " - 83s - loss: 0.0198 - acc: 0.9930 - val_loss: 4.2932 - val_acc: 0.1429\n",
            "Epoch 26/100\n",
            " - 82s - loss: 0.0205 - acc: 0.9942 - val_loss: 4.0944 - val_acc: 0.1429\n",
            "Epoch 27/100\n",
            " - 86s - loss: 0.0253 - acc: 0.9942 - val_loss: 4.2250 - val_acc: 0.1429\n",
            "Epoch 28/100\n",
            " - 84s - loss: 0.0202 - acc: 0.9936 - val_loss: 3.9949 - val_acc: 0.1429\n",
            "Epoch 29/100\n",
            " - 82s - loss: 0.0170 - acc: 0.9936 - val_loss: 4.0039 - val_acc: 0.1429\n",
            "Epoch 30/100\n",
            " - 85s - loss: 0.0282 - acc: 0.9919 - val_loss: 4.0748 - val_acc: 0.1429\n",
            "Epoch 31/100\n",
            " - 84s - loss: 0.0236 - acc: 0.9909 - val_loss: 4.1722 - val_acc: 0.1429\n",
            "Epoch 32/100\n",
            " - 83s - loss: 0.0279 - acc: 0.9918 - val_loss: 3.9526 - val_acc: 0.1429\n",
            "Epoch 33/100\n",
            " - 85s - loss: 0.0249 - acc: 0.9920 - val_loss: 3.8650 - val_acc: 0.1429\n",
            "Epoch 34/100\n",
            " - 83s - loss: 0.0188 - acc: 0.9949 - val_loss: 4.1097 - val_acc: 0.1429\n",
            "Epoch 35/100\n",
            " - 83s - loss: 0.0225 - acc: 0.9936 - val_loss: 4.0210 - val_acc: 0.1429\n",
            "Epoch 36/100\n",
            " - 85s - loss: 0.0202 - acc: 0.9950 - val_loss: 4.3823 - val_acc: 0.1429\n",
            "Epoch 37/100\n",
            " - 83s - loss: 0.0168 - acc: 0.9953 - val_loss: 4.2633 - val_acc: 0.1429\n",
            "Epoch 38/100\n",
            " - 83s - loss: 0.0162 - acc: 0.9945 - val_loss: 4.3453 - val_acc: 0.1429\n",
            "Epoch 39/100\n",
            " - 85s - loss: 0.0228 - acc: 0.9939 - val_loss: 4.3486 - val_acc: 0.1429\n",
            "Epoch 40/100\n",
            " - 83s - loss: 0.0249 - acc: 0.9922 - val_loss: 4.7438 - val_acc: 0.1429\n",
            "Epoch 41/100\n",
            " - 83s - loss: 0.0156 - acc: 0.9950 - val_loss: 4.9025 - val_acc: 0.1429\n",
            "Epoch 42/100\n",
            " - 85s - loss: 0.0161 - acc: 0.9940 - val_loss: 4.7352 - val_acc: 0.1429\n",
            "Epoch 43/100\n",
            " - 83s - loss: 0.0200 - acc: 0.9943 - val_loss: 4.6605 - val_acc: 0.1429\n",
            "Epoch 44/100\n",
            " - 82s - loss: 0.0180 - acc: 0.9950 - val_loss: 4.8412 - val_acc: 0.1429\n",
            "Epoch 45/100\n",
            " - 85s - loss: 0.0149 - acc: 0.9960 - val_loss: 4.4626 - val_acc: 0.1429\n",
            "Epoch 46/100\n",
            " - 83s - loss: 0.0165 - acc: 0.9943 - val_loss: 4.9381 - val_acc: 0.1429\n",
            "Epoch 47/100\n",
            " - 82s - loss: 0.0158 - acc: 0.9952 - val_loss: 5.0426 - val_acc: 0.1429\n",
            "Epoch 48/100\n",
            " - 85s - loss: 0.0162 - acc: 0.9951 - val_loss: 5.3724 - val_acc: 0.1429\n",
            "Epoch 49/100\n",
            " - 82s - loss: 0.0093 - acc: 0.9960 - val_loss: 5.1214 - val_acc: 0.1429\n",
            "Epoch 50/100\n",
            " - 83s - loss: 0.0163 - acc: 0.9957 - val_loss: 5.5873 - val_acc: 0.1429\n",
            "Epoch 51/100\n",
            " - 85s - loss: 0.0160 - acc: 0.9946 - val_loss: 5.1991 - val_acc: 0.1429\n",
            "Epoch 52/100\n",
            " - 83s - loss: 0.0162 - acc: 0.9954 - val_loss: 5.2357 - val_acc: 0.1429\n",
            "Epoch 53/100\n",
            " - 83s - loss: 0.0113 - acc: 0.9965 - val_loss: 5.2818 - val_acc: 0.1429\n",
            "Epoch 54/100\n",
            " - 86s - loss: 0.0172 - acc: 0.9951 - val_loss: 5.5870 - val_acc: 0.1429\n",
            "Epoch 55/100\n",
            " - 83s - loss: 0.0181 - acc: 0.9948 - val_loss: 5.9582 - val_acc: 0.1429\n",
            "Epoch 56/100\n",
            " - 83s - loss: 0.0107 - acc: 0.9967 - val_loss: 5.6934 - val_acc: 0.1429\n",
            "Epoch 57/100\n",
            " - 86s - loss: 0.0164 - acc: 0.9965 - val_loss: 5.7735 - val_acc: 0.1429\n",
            "Epoch 58/100\n",
            " - 83s - loss: 0.0147 - acc: 0.9962 - val_loss: 5.8243 - val_acc: 0.1429\n",
            "Epoch 59/100\n",
            " - 83s - loss: 0.0131 - acc: 0.9963 - val_loss: 6.0227 - val_acc: 0.1429\n",
            "Epoch 60/100\n",
            " - 86s - loss: 0.0178 - acc: 0.9956 - val_loss: 5.6519 - val_acc: 0.1429\n",
            "Epoch 61/100\n",
            " - 84s - loss: 0.0085 - acc: 0.9964 - val_loss: 5.9064 - val_acc: 0.1429\n",
            "Epoch 62/100\n",
            " - 83s - loss: 0.0136 - acc: 0.9963 - val_loss: 5.6538 - val_acc: 0.1429\n",
            "Epoch 63/100\n",
            " - 86s - loss: 0.0121 - acc: 0.9957 - val_loss: 5.6752 - val_acc: 0.1429\n",
            "Epoch 64/100\n",
            " - 83s - loss: 0.0092 - acc: 0.9966 - val_loss: 6.0173 - val_acc: 0.1429\n",
            "Epoch 65/100\n",
            " - 83s - loss: 0.0139 - acc: 0.9960 - val_loss: 5.8908 - val_acc: 0.1429\n",
            "Epoch 66/100\n",
            " - 86s - loss: 0.0107 - acc: 0.9958 - val_loss: 5.8811 - val_acc: 0.1429\n",
            "Epoch 67/100\n",
            " - 83s - loss: 0.0164 - acc: 0.9965 - val_loss: 6.0394 - val_acc: 0.1429\n",
            "Epoch 68/100\n",
            " - 83s - loss: 0.0112 - acc: 0.9957 - val_loss: 5.8931 - val_acc: 0.1429\n",
            "Epoch 69/100\n",
            " - 85s - loss: 0.0118 - acc: 0.9970 - val_loss: 5.7808 - val_acc: 0.1429\n",
            "Epoch 70/100\n",
            " - 83s - loss: 0.0103 - acc: 0.9966 - val_loss: 6.2481 - val_acc: 0.1429\n",
            "Epoch 71/100\n",
            " - 83s - loss: 0.0222 - acc: 0.9950 - val_loss: 6.4077 - val_acc: 0.1429\n",
            "Epoch 72/100\n",
            " - 86s - loss: 0.0108 - acc: 0.9963 - val_loss: 6.2822 - val_acc: 0.1429\n",
            "Epoch 73/100\n",
            " - 83s - loss: 0.0127 - acc: 0.9960 - val_loss: 6.2858 - val_acc: 0.1429\n",
            "Epoch 74/100\n",
            " - 83s - loss: 0.0128 - acc: 0.9969 - val_loss: 6.6275 - val_acc: 0.1429\n",
            "Epoch 75/100\n",
            " - 86s - loss: 0.0084 - acc: 0.9977 - val_loss: 6.9613 - val_acc: 0.1429\n",
            "Epoch 76/100\n",
            " - 84s - loss: 0.0130 - acc: 0.9969 - val_loss: 7.1624 - val_acc: 0.1429\n",
            "Epoch 77/100\n",
            " - 83s - loss: 0.0108 - acc: 0.9965 - val_loss: 6.9787 - val_acc: 0.1429\n",
            "Epoch 78/100\n",
            " - 86s - loss: 0.0117 - acc: 0.9967 - val_loss: 7.1677 - val_acc: 0.1429\n",
            "Epoch 79/100\n",
            " - 84s - loss: 0.0076 - acc: 0.9975 - val_loss: 7.1865 - val_acc: 0.1429\n",
            "Epoch 80/100\n",
            " - 84s - loss: 0.0068 - acc: 0.9977 - val_loss: 7.0722 - val_acc: 0.1429\n",
            "Epoch 81/100\n",
            " - 85s - loss: 0.0157 - acc: 0.9963 - val_loss: 6.4980 - val_acc: 0.1429\n",
            "Epoch 82/100\n",
            " - 84s - loss: 0.0121 - acc: 0.9962 - val_loss: 6.6045 - val_acc: 0.1429\n",
            "Epoch 83/100\n",
            " - 84s - loss: 0.0104 - acc: 0.9968 - val_loss: 6.2030 - val_acc: 0.1429\n",
            "Epoch 84/100\n",
            " - 85s - loss: 0.0093 - acc: 0.9966 - val_loss: 6.5648 - val_acc: 0.1429\n",
            "Epoch 85/100\n",
            " - 83s - loss: 0.0074 - acc: 0.9979 - val_loss: 6.5781 - val_acc: 0.1429\n",
            "Epoch 86/100\n",
            " - 83s - loss: 0.0074 - acc: 0.9977 - val_loss: 6.6280 - val_acc: 0.1429\n",
            "Epoch 87/100\n",
            " - 86s - loss: 0.0103 - acc: 0.9967 - val_loss: 6.0843 - val_acc: 0.1429\n",
            "Epoch 88/100\n",
            " - 83s - loss: 0.0128 - acc: 0.9969 - val_loss: 6.5825 - val_acc: 0.1429\n",
            "Epoch 89/100\n",
            " - 83s - loss: 0.0129 - acc: 0.9970 - val_loss: 6.5650 - val_acc: 0.1429\n",
            "Epoch 90/100\n",
            " - 85s - loss: 0.0107 - acc: 0.9974 - val_loss: 6.8283 - val_acc: 0.1429\n",
            "Epoch 91/100\n",
            " - 83s - loss: 0.0075 - acc: 0.9979 - val_loss: 6.8758 - val_acc: 0.1429\n",
            "Epoch 92/100\n",
            " - 83s - loss: 0.0163 - acc: 0.9967 - val_loss: 7.1041 - val_acc: 0.1429\n",
            "Epoch 93/100\n",
            " - 85s - loss: 0.0093 - acc: 0.9964 - val_loss: 7.3565 - val_acc: 0.1429\n",
            "Epoch 94/100\n",
            " - 82s - loss: 0.0060 - acc: 0.9976 - val_loss: 7.0517 - val_acc: 0.1429\n",
            "Epoch 95/100\n",
            " - 82s - loss: 0.0121 - acc: 0.9969 - val_loss: 7.1975 - val_acc: 0.1429\n",
            "Epoch 96/100\n",
            " - 85s - loss: 0.0087 - acc: 0.9973 - val_loss: 7.1992 - val_acc: 0.1429\n",
            "Epoch 97/100\n",
            " - 82s - loss: 0.0066 - acc: 0.9980 - val_loss: 7.6134 - val_acc: 0.1429\n",
            "Epoch 98/100\n",
            " - 82s - loss: 0.0057 - acc: 0.9981 - val_loss: 7.7832 - val_acc: 0.1429\n",
            "Epoch 99/100\n",
            " - 85s - loss: 0.0079 - acc: 0.9974 - val_loss: 7.8524 - val_acc: 0.1429\n",
            "Epoch 100/100\n",
            " - 83s - loss: 0.0130 - acc: 0.9974 - val_loss: 7.8191 - val_acc: 0.1429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKxEWOx2E4CC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1avsuB8cA-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/KerasTask/data/1203_pantsmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuwkBVsMcE9a",
        "colab_type": "code",
        "outputId": "bb1de689-1cf4-4da6-8ddc-c0f3b8be875f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n55LmOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnItxHqidcy7GeaB2zrkY54HaOedi3P8DbTVYFkS26BYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYbsNvI-cJF7",
        "colab_type": "code",
        "outputId": "113401e5-9058-45b6-c318-edfd18b97f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZzxZnFjcLig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyO4wqWpcNfw",
        "colab_type": "code",
        "outputId": "ab458699-64ff-4809-aba7-50f945074ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=200,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 1.3533 - val_acc: 0.8643\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 87s 433ms/step - loss: 0.0127 - acc: 0.9974 - val_loss: 1.3294 - val_acc: 0.8643\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 1.3421 - val_acc: 0.8714\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 1.1577 - val_acc: 0.8643\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 1.3957 - val_acc: 0.8500\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 1.5192 - val_acc: 0.8571\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 1.5015 - val_acc: 0.8500\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 1.4146 - val_acc: 0.8571\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 1.2297 - val_acc: 0.8714\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 1.2745 - val_acc: 0.8714\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 87s 434ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 1.2762 - val_acc: 0.8786\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 1.2620 - val_acc: 0.8714\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 1.3385 - val_acc: 0.8714\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 1.2255 - val_acc: 0.8786\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 1.2486 - val_acc: 0.8786\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 1.2756 - val_acc: 0.8643\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 1.3812 - val_acc: 0.8571\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 1.3588 - val_acc: 0.8643\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 1.3365 - val_acc: 0.8571\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 87s 433ms/step - loss: 0.0110 - acc: 0.9982 - val_loss: 1.4907 - val_acc: 0.8429\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.0048 - acc: 0.9980 - val_loss: 1.3892 - val_acc: 0.8500\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0058 - acc: 0.9979 - val_loss: 1.4221 - val_acc: 0.8643\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0061 - acc: 0.9977 - val_loss: 1.3294 - val_acc: 0.8500\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0033 - acc: 0.9986 - val_loss: 1.4427 - val_acc: 0.8500\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 1.3511 - val_acc: 0.8714\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 1.3111 - val_acc: 0.8500\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 1.2806 - val_acc: 0.8857\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 1.2796 - val_acc: 0.8643\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 1.3498 - val_acc: 0.8643\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 1.3297 - val_acc: 0.8786\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0124 - acc: 0.9983 - val_loss: 1.2610 - val_acc: 0.8714\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 1.3061 - val_acc: 0.8714\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 1.4038 - val_acc: 0.8714\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 1.3842 - val_acc: 0.8714\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 1.4017 - val_acc: 0.8643\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 1.4414 - val_acc: 0.8714\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.3637 - val_acc: 0.8643\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 87s 434ms/step - loss: 0.0068 - acc: 0.9989 - val_loss: 1.4810 - val_acc: 0.8429\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 89s 446ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 1.2678 - val_acc: 0.8714\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 89s 447ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 1.3589 - val_acc: 0.8643\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 1.2548 - val_acc: 0.8571\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0067 - acc: 0.9987 - val_loss: 1.3324 - val_acc: 0.8571\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 1.3044 - val_acc: 0.8643\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.0053 - acc: 0.9990 - val_loss: 1.3802 - val_acc: 0.8643\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.3917 - val_acc: 0.8714\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 1.3244 - val_acc: 0.8714\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 1.3861 - val_acc: 0.8643\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 91s 455ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 1.4195 - val_acc: 0.8643\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 1.3713 - val_acc: 0.8643\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 1.3659 - val_acc: 0.8571\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 90s 452ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 1.3639 - val_acc: 0.8643\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0032 - acc: 0.9985 - val_loss: 1.3920 - val_acc: 0.8643\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.0049 - acc: 0.9992 - val_loss: 1.2824 - val_acc: 0.8643\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.0062 - acc: 0.9986 - val_loss: 1.4965 - val_acc: 0.8571\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 1.4049 - val_acc: 0.8571\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0035 - acc: 0.9986 - val_loss: 1.3073 - val_acc: 0.8786\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 1.3672 - val_acc: 0.8786\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 1.3389 - val_acc: 0.8714\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0045 - acc: 0.9992 - val_loss: 1.3321 - val_acc: 0.8714\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 1.5258 - val_acc: 0.8357\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 88s 441ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 1.3828 - val_acc: 0.8571\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 1.3692 - val_acc: 0.8714\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 0.0076 - acc: 0.9982 - val_loss: 1.4011 - val_acc: 0.8571\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0035 - acc: 0.9986 - val_loss: 1.3998 - val_acc: 0.8786\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0029 - acc: 0.9987 - val_loss: 1.3959 - val_acc: 0.8643\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 1.4841 - val_acc: 0.8571\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 1.4568 - val_acc: 0.8714\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 1.5265 - val_acc: 0.8500\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 1.3894 - val_acc: 0.8714\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 1.3858 - val_acc: 0.8786\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0092 - acc: 0.9985 - val_loss: 1.3333 - val_acc: 0.8714\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 1.3995 - val_acc: 0.8571\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.4871 - val_acc: 0.8643\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 1.3339 - val_acc: 0.8857\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.5193 - val_acc: 0.8500\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 1.3238 - val_acc: 0.8786\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 1.2947 - val_acc: 0.8786\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 1.2513 - val_acc: 0.8786\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 1.3627 - val_acc: 0.8714\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 1.3560 - val_acc: 0.8786\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.3289 - val_acc: 0.8786\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 89s 444ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 1.3889 - val_acc: 0.8714\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 88s 440ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 1.3426 - val_acc: 0.8714\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 90s 452ms/step - loss: 2.7289e-04 - acc: 1.0000 - val_loss: 1.3957 - val_acc: 0.8714\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 1.4989 - val_acc: 0.8500\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 88s 438ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 1.4945 - val_acc: 0.8571\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 1.4818 - val_acc: 0.8500\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 87s 436ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.4527 - val_acc: 0.8571\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 86s 430ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.4798 - val_acc: 0.8643\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 88s 442ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 1.4163 - val_acc: 0.8786\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 86s 430ms/step - loss: 0.0024 - acc: 0.9991 - val_loss: 1.3599 - val_acc: 0.8714\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 87s 435ms/step - loss: 0.0038 - acc: 0.9995 - val_loss: 1.3483 - val_acc: 0.8786\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 89s 445ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 1.3624 - val_acc: 0.8643\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 1.4476 - val_acc: 0.8571\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 88s 439ms/step - loss: 0.0087 - acc: 0.9983 - val_loss: 1.4046 - val_acc: 0.8714\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 89s 443ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 1.3243 - val_acc: 0.8714\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 87s 433ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 1.3575 - val_acc: 0.8714\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 85s 425ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 1.3768 - val_acc: 0.8786\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 87s 437ms/step - loss: 0.0074 - acc: 0.9987 - val_loss: 1.3752 - val_acc: 0.8714\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 86s 430ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 1.3436 - val_acc: 0.8714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00e_zmUpcWsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('1204_pantmodel_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q-EN8KI9lwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "09b3ce77-20eb-482b-9987-0cc4f50a78bf"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXNAdx3HSBBd0x3GcNMEF3XEcJ034/7nttk7dwgSrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvesteUC_7d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "54adf930-8137-456e-af21-ad18002ebee6"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 77 images belonging to 7 classes.\n",
            "test acc: 0.9470954286359653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpE5cVtA_-uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}